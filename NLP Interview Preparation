1. How Word2Vec Works, AvgWord2Vec?
2. Types of Word2Vec?
3. What will be output of Word2Vec?
4. Difference between Word2Vec and TFIDF for custom corpus
5. Corpus vs Documents
6. What are Tokenization and Embeddings?
7. Types of tokenization, Different types of tokenization related to bert (Pretrained tokenization)
8. Benefits of Bert over RNN or LSTM
how dropout can be applied in these lstm
9. How to handle time out in LLM models? Langchain solution for it...
10. What are benefits of LLM model? Why we uses LLM over bert in chatbots?
11. Lemmatisation vs Stemming, what are different types of them?
12. Different types of prompts (Prompt Engineering).
13. How to handle imbalance dataset in text?
14. How to handle overfitting and Underfitting dataset in text?
15. What are pretrained embedding models?
16. What are vector store DB? Mention benefits.
17. Which is better Dense or Sparse vector?
18. Attention Mechanism, Difference between multi head attention, and cross head attention. 

## UseCases
create a lstm network training for next charaxter prediction or next word prediction
1. Perform document classification, on a number of documents, no classes are given.
2. How chatbot will work, we only have 30 Questions and 30 related answers?

## Generative AI
1. Generate SQL or Pandas query for a statement, Perform query correction, and time managemement after performing multiple queries.
2. Open AI API uses to generate different templates
